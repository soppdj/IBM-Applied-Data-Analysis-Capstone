{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Data Wrangling Lab**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Title     : Data wrangling Lab\n",
    "    Author    : Sopianto Djahar\n",
    "    Email     : idnsopianto@gmail.com\n",
    "    Linkedin  : https://www.linkedin.com/in/sopiantodjahar/\n",
    "    GitHub    : github.com/soppdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Identify duplicate values in the dataset.\n",
    "\n",
    "-   Remove duplicate values from the dataset.\n",
    "\n",
    "-   Identify missing values in the dataset.\n",
    "\n",
    "-   Impute the missing values in the dataset.\n",
    "\n",
    "-   Normalize data in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands on Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We utilize the pandas.read_csv() function for reading CSV files. However, in this version of the lab, which operates on JupyterLite, the dataset needs to be downloaded to the interface using the provided code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions below will download the dataset into your browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the dataset\n",
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain the dataset, utilize the download() function as defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded and saved as 'm1_survey_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the content of the response into a CSV file\n",
    "with open(\"m1_survey_data.csv\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "print(\"Dataset downloaded and saved as 'm1_survey_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize the Pandas method read_csv() to load the data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"m1_survey_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respondent       int64\n",
      "MainBranch      object\n",
      "Hobbyist        object\n",
      "OpenSourcer     object\n",
      "OpenSource      object\n",
      "                 ...  \n",
      "Sexuality       object\n",
      "Ethnicity       object\n",
      "Dependents      object\n",
      "SurveyLength    object\n",
      "SurveyEase      object\n",
      "Length: 85, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the data types of all columns\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you will identify duplicate values in the dataset.\n",
    "\n",
    "Find how many duplicate rows exist in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of duplicate rows in the dataframe is: 154\n"
     ]
    }
   ],
   "source": [
    "# Find the number of duplicate rows in the DataFrame\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(\"The number of duplicate rows in the dataframe is:\", num_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in the dataset is: 11552\n"
     ]
    }
   ],
   "source": [
    "num_rows = df.shape[0]\n",
    "\n",
    "print(f\"Number of rows before removing duplicates: {num_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the duplicate rows from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "df1 = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if duplicates were actually dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after removing duplicates: 11398\n"
     ]
    }
   ],
   "source": [
    "# Check the number of rows after removing duplicates\n",
    "print(\"Number of rows after removing duplicates:\", df1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the missing values for all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the number of missing values for each column\n",
    "missing_values = df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSource         81\n",
      "Student            51\n",
      "EdLevel           112\n",
      "UndergradMajor    737\n",
      "EduOther          164\n",
      "                 ... \n",
      "Sexuality         542\n",
      "Ethnicity         675\n",
      "Dependents        140\n",
      "SurveyLength       19\n",
      "SurveyEase         14\n",
      "Length: 73, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter to show only columns with missing values\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "# Display the missing values\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how many rows are missing in the column 'WorkLoc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values in the 'WorkLoc' column is: 32\n"
     ]
    }
   ],
   "source": [
    "# Find the number of missing values in the 'WorkLoc' column\n",
    "missing_workloc = df1['WorkLoc'].isnull().sum()\n",
    "\n",
    "# Display the number of missing values\n",
    "print(f\"The number of missing values in the 'WorkLoc' column is: {missing_workloc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imputing missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the value counts for the column WorkLoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorkLoc\n",
      "Office                                            6806\n",
      "Home                                              3589\n",
      "Other place, such as a coworking space or cafe     971\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the value counts for the 'WorkLoc' column\n",
    "workloc_counts = df1['WorkLoc'].value_counts()\n",
    "\n",
    "# Display the value counts\n",
    "print(workloc_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the value that is most frequent (majority) in the WorkLoc column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent value in the 'WorkLoc' column is 'Office' with a count of 6806.\n"
     ]
    }
   ],
   "source": [
    "# Identify the most frequent value\n",
    "most_frequent_workloc = workloc_counts.idxmax()\n",
    "most_frequent_count = workloc_counts.max()\n",
    "\n",
    "# Display the most frequent value and its count\n",
    "print(f\"The most frequent value in the 'WorkLoc' column is '{most_frequent_workloc}' with a count of {most_frequent_count}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent value in the 'WorkLoc' column is 'Office'.\n"
     ]
    }
   ],
   "source": [
    "# Identify the most frequent value\n",
    "most_frequent_workloc = workloc_counts.idxmax()\n",
    "\n",
    "# Display the most frequent value\n",
    "print(f\"The most frequent value in the 'WorkLoc' column is '{most_frequent_workloc}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'WorkLoc' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Impute the missing values in 'WorkLoc' column with the most frequent value\n",
    "df['WorkLoc'].fillna(most_frequent_workloc, inplace=True)\n",
    "\n",
    "# Check if there are any missing values left in 'WorkLoc'\n",
    "missing_workloc_count = df['WorkLoc'].isna().sum()\n",
    "print(f\"Number of missing values in 'WorkLoc' after imputation: {missing_workloc_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv(\"m1_survey_data_imputed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two columns in the dataset that talk about compensation.\n",
    "\n",
    "One is \"CompFreq\". This column shows how often a developer is paid (Yearly, Monthly, Weekly).\n",
    "\n",
    "The other is \"CompTotal\". This column talks about how much the developer is paid per Year, Month, or Week depending upon his/her \"CompFreq\".\n",
    "\n",
    "This makes it difficult to compare the total compensation of the developers.\n",
    "\n",
    "In this section you will create a new column called 'NormalizedAnnualCompensation' which contains the 'Annual Compensation' irrespective of the 'CompFreq'.\n",
    "\n",
    "Once this column is ready, it makes comparison of salaries easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List out the various categories in the column 'CompFreq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in 'CompFreq': ['Yearly' 'Monthly' 'Weekly' nan]\n"
     ]
    }
   ],
   "source": [
    "# List out the various categories in the 'CompFreq' column\n",
    "comp_freq_categories = df['CompFreq'].unique()\n",
    "print(f\"Categories in 'CompFreq': {comp_freq_categories}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named 'NormalizedAnnualCompensation'. Use the hint given below if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to normalize the compensation\n",
    "def normalize_compensation(row):\n",
    "    if row['CompFreq'] == 'Yearly':\n",
    "        return row['CompTotal']\n",
    "    elif row['CompFreq'] == 'Monthly':\n",
    "        return row['CompTotal'] * 12\n",
    "    elif row['CompFreq'] == 'Weekly':\n",
    "        return row['CompTotal'] * 52\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CompFreq  CompTotal  NormalizedAnnualCompensation\n",
      "0   Yearly    61000.0                       61000.0\n",
      "1   Yearly   138000.0                      138000.0\n",
      "2   Yearly    90000.0                       90000.0\n",
      "3  Monthly    29000.0                      348000.0\n",
      "4   Yearly    90000.0                       90000.0\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to create the 'NormalizedAnnualCompensation' column\n",
    "df['NormalizedAnnualCompensation'] = df.apply(normalize_compensation, axis=1)\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(df[['CompFreq', 'CompTotal', 'NormalizedAnnualCompensation']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv(\"m1_survey_data_normalized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright © 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
